{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "# %matplotlib inline 可以在Ipython编译器里直接使用，功能是可以内嵌绘图，并且可以省略掉plt.show()这一步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "input_size = 28 # 图像的总尺寸\n",
    "num_classes = 10 # 标签的种类数\n",
    "num_epochs = 3 # 训练的总循环周期\n",
    "batch_size = 64\n",
    "\n",
    "# 训练集\n",
    "train_dataset = datasets.MNIST(root='./data',\n",
    "                            train=True,\n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "# 测试集\n",
    "test_dataset = datasets.MNIST(root='./data',\n",
    "                            train=False,\n",
    "                            transform=transforms.ToTensor())\n",
    "\n",
    "# 构建 batch 数据\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{(h - filterSize + padding * 2)}{stride} + 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential( # 输入大小(1, 28, 28)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1, #灰度图\n",
    "                out_channels=16, # 得到的特征图个数\n",
    "                kernel_size=5, # 卷积核大小\n",
    "                stride=1, # 步长\n",
    "                padding=2 # 如果希望卷积后大小跟原来一样，需要设置 padding = (kernel_size - 1) / 2 if stride = 1\n",
    "            ),\n",
    "\n",
    "            nn.ReLU(), # relu 层\n",
    "            nn.MaxPool2d(kernel_size=2) # 池化操作（2 x 2 区域），输出结果为 （16， 14， 14）\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 5, 1, 2), # 输入 （16， 14， 14）\n",
    "            nn.ReLU(), # relu 层\n",
    "            nn.MaxPool2d(2) # 输出 （32， 7， 7）\n",
    "        )\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10) # 全连接层得到结果\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1) # flatten 操作，结果为：（batch_size, 32 * 7 * 7)\n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准确率作为评估标准\n",
    "- torch.max(a,1) 返回每一行中最大值的那个元素，且返回其索引\n",
    "- torch.max()[0]， 只返回最大值的每个数\n",
    "- troch.max()[1]， 只返回最大值的每个索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    pred = torch.max(predictions.data, 1)[1]\n",
    "    rights = pred.eq(labels.data.view_as(pred)).sum()\n",
    "    return rights, len(labels) # 正确预测的结果个数，总的结果个数"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前 epoch: 0 [0/60000(0%)]\t损失: 2.304555\t训练集准确率: 9.38%\t测试集准确率: 11.77%\n",
      "当前 epoch: 0 [6400/60000(11%)]\t损失: 0.244132\t训练集准确率: 75.14%\t测试集准确率: 91.42%\n",
      "当前 epoch: 0 [12800/60000(21%)]\t损失: 0.137795\t训练集准确率: 84.26%\t测试集准确率: 95.14%\n",
      "当前 epoch: 0 [19200/60000(32%)]\t损失: 0.132530\t训练集准确率: 87.94%\t测试集准确率: 96.48%\n",
      "当前 epoch: 0 [25600/60000(43%)]\t损失: 0.173722\t训练集准确率: 89.92%\t测试集准确率: 97.01%\n",
      "当前 epoch: 0 [32000/60000(53%)]\t损失: 0.064016\t训练集准确率: 91.27%\t测试集准确率: 97.17%\n",
      "当前 epoch: 0 [38400/60000(64%)]\t损失: 0.020512\t训练集准确率: 92.27%\t测试集准确率: 97.66%\n",
      "当前 epoch: 0 [44800/60000(75%)]\t损失: 0.122267\t训练集准确率: 93.01%\t测试集准确率: 97.83%\n",
      "当前 epoch: 0 [51200/60000(85%)]\t损失: 0.061263\t训练集准确率: 93.57%\t测试集准确率: 97.83%\n",
      "当前 epoch: 0 [57600/60000(96%)]\t损失: 0.123808\t训练集准确率: 94.04%\t测试集准确率: 98.20%\n",
      "当前 epoch: 1 [0/60000(0%)]\t损失: 0.107763\t训练集准确率: 98.44%\t测试集准确率: 98.25%\n",
      "当前 epoch: 1 [6400/60000(11%)]\t损失: 0.069549\t训练集准确率: 98.05%\t测试集准确率: 98.18%\n",
      "当前 epoch: 1 [12800/60000(21%)]\t损失: 0.054784\t训练集准确率: 97.88%\t测试集准确率: 98.42%\n",
      "当前 epoch: 1 [19200/60000(32%)]\t损失: 0.076677\t训练集准确率: 98.08%\t测试集准确率: 98.31%\n",
      "当前 epoch: 1 [25600/60000(43%)]\t损失: 0.031533\t训练集准确率: 98.14%\t测试集准确率: 98.46%\n",
      "当前 epoch: 1 [32000/60000(53%)]\t损失: 0.116314\t训练集准确率: 98.14%\t测试集准确率: 98.72%\n",
      "当前 epoch: 1 [38400/60000(64%)]\t损失: 0.012457\t训练集准确率: 98.17%\t测试集准确率: 98.55%\n",
      "当前 epoch: 1 [44800/60000(75%)]\t损失: 0.131312\t训练集准确率: 98.18%\t测试集准确率: 98.38%\n",
      "当前 epoch: 1 [51200/60000(85%)]\t损失: 0.080673\t训练集准确率: 98.21%\t测试集准确率: 98.73%\n",
      "当前 epoch: 1 [57600/60000(96%)]\t损失: 0.102469\t训练集准确率: 98.27%\t测试集准确率: 98.63%\n",
      "当前 epoch: 2 [0/60000(0%)]\t损失: 0.082175\t训练集准确率: 98.44%\t测试集准确率: 98.59%\n",
      "当前 epoch: 2 [6400/60000(11%)]\t损失: 0.017586\t训练集准确率: 98.59%\t测试集准确率: 98.71%\n",
      "当前 epoch: 2 [12800/60000(21%)]\t损失: 0.014688\t训练集准确率: 98.58%\t测试集准确率: 98.66%\n",
      "当前 epoch: 2 [19200/60000(32%)]\t损失: 0.036948\t训练集准确率: 98.61%\t测试集准确率: 98.77%\n",
      "当前 epoch: 2 [25600/60000(43%)]\t损失: 0.108010\t训练集准确率: 98.64%\t测试集准确率: 98.71%\n",
      "当前 epoch: 2 [32000/60000(53%)]\t损失: 0.061355\t训练集准确率: 98.68%\t测试集准确率: 98.97%\n",
      "当前 epoch: 2 [38400/60000(64%)]\t损失: 0.040263\t训练集准确率: 98.68%\t测试集准确率: 98.93%\n",
      "当前 epoch: 2 [44800/60000(75%)]\t损失: 0.024451\t训练集准确率: 98.72%\t测试集准确率: 98.99%\n",
      "当前 epoch: 2 [51200/60000(85%)]\t损失: 0.029003\t训练集准确率: 98.69%\t测试集准确率: 98.92%\n",
      "当前 epoch: 2 [57600/60000(96%)]\t损失: 0.009982\t训练集准确率: 98.71%\t测试集准确率: 98.87%\n"
     ]
    }
   ],
   "source": [
    "# 实例化\n",
    "net = CNN()\n",
    "# 损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 优化器\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001) # 普通的随机梯度下降算法\n",
    "\n",
    "# 开始训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    # 当前 epoch 的结果保存下来\n",
    "    train_rights = []\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader): # 针对容器的每一个批进行循环\n",
    "        net.train()\n",
    "        output = net(data)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        right = accuracy(output, target)\n",
    "        train_rights.append(right)\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            net.eval()\n",
    "            val_rights = []\n",
    "            for (data, target) in test_loader:\n",
    "                output = net(data)\n",
    "                right = accuracy(output, target)\n",
    "                val_rights.append(right) # append tuples\n",
    "\n",
    "            # 准确率计算\n",
    "            train_r = (sum([tup[0] for tup in train_rights]), sum([tup[1] for tup in train_rights]))\n",
    "            val_r = (sum([tup[0] for tup in val_rights]), sum([tup[1] for tup in val_rights]))\n",
    "\n",
    "            print('当前 epoch: {} [{}/{}({:.0f}%)]\\t损失: {:.6f}\\t训练集准确率: {:.2f}%\\t测试集准确率: {:.2f}%'.format(\n",
    "                epoch,\n",
    "                batch_idx * batch_size,\n",
    "                len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.data,\n",
    "                100. * train_r[0].numpy() / train_r[1],\n",
    "                100. * val_r[0].numpy() / val_r[1]\n",
    "            ))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
