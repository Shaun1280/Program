{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3062, -0.2004, -2.3097, -2.2580],\n",
       "        [ 0.6715, -1.2551,  1.1644, -1.7252],\n",
       "        [-0.7398, -1.2618,  0.1555,  0.1586]], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method 1\n",
    "x = torch.randn(3, 4, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7330,  0.0479,  1.0397,  0.0680],\n",
       "        [-0.0436,  0.8306,  0.4466,  1.6647],\n",
       "        [ 1.5288, -1.9899, -2.0221, -1.0470]], requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method 2\n",
    "x = torch.randn(3, 4)\n",
    "x.requires_grad = True\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randn(3, 4, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.9315, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = t.sum()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t = x + b 对 b 求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用到的 t 的 requires_grad 也会变为 true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.requires_grad, b.requires_grad, t.requires_grad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/chain.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1)\n",
    "b = torch.rand(1, requires_grad=True)\n",
    "w = torch.rand(1, requires_grad=True)\n",
    "\n",
    "y = w * x\n",
    "z = y + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True, True, True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.requires_grad, b.requires_grad, w.requires_grad, y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True, False, False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.is_leaf, w.is_leaf, b.is_leaf, y.is_leaf, z.is_leaf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "反向传播计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward(retain_graph=True) # 不清空梯度，会累加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2809])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归 https://blog.csdn.net/hgnuxc_1993/article/details/115046874"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_values = [i for i in range (11)]\n",
    "x_train = np.array(x_values, dtype=np.float32)\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_values = [2 * i + 1 for i in x_values]\n",
    "y_train = np.array(y_values, dtype=np.float32)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归模型\n",
    "  - 其实线性回归就是一个不加激活函数的全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "output_dim = 1\n",
    "\n",
    "model = LinearRegressionModel(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegressionModel(\n",
       "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss() # Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50, loss 9.676247714196506e-08\n",
      "epoch 100, loss 5.5141018862059354e-08\n",
      "epoch 150, loss 3.154044847519799e-08\n",
      "epoch 200, loss 1.8006669932901787e-08\n",
      "epoch 250, loss 1.0317020127104115e-08\n",
      "epoch 300, loss 5.881231945892296e-09\n",
      "epoch 350, loss 3.3407603350354975e-09\n",
      "epoch 400, loss 1.915149150377715e-09\n",
      "epoch 450, loss 1.114575765015502e-09\n",
      "epoch 500, loss 6.271495545107086e-10\n",
      "epoch 550, loss 3.6789060686714947e-10\n",
      "epoch 600, loss 2.14025810962859e-10\n",
      "epoch 650, loss 1.2437630092509977e-10\n",
      "epoch 700, loss 7.471292334804147e-11\n",
      "epoch 750, loss 4.55835785784231e-11\n",
      "epoch 800, loss 2.911707333574931e-11\n",
      "epoch 850, loss 1.5593505653388462e-11\n",
      "epoch 900, loss 1.5593505653388462e-11\n",
      "epoch 950, loss 1.5593505653388462e-11\n",
      "epoch 1000, loss 1.5593505653388462e-11\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    epoch += 1\n",
    "\n",
    "    inputs = torch.from_numpy(x_train)\n",
    "    labels = torch.from_numpy(y_train)\n",
    "    \n",
    "    # 每一次迭代 梯度清零\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 前向传播\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # 计算损失\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # 反向传播\n",
    "    loss.backward()\n",
    "\n",
    "    # 更新权重参数\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99999267],\n",
       "       [ 2.9999938 ],\n",
       "       [ 4.999995  ],\n",
       "       [ 6.9999967 ],\n",
       "       [ 8.999997  ],\n",
       "       [10.999998  ],\n",
       "       [13.        ],\n",
       "       [15.000001  ],\n",
       "       [17.000002  ],\n",
       "       [19.000004  ],\n",
       "       [21.000004  ]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model(torch.from_numpy(x_train).requires_grad_()).data.numpy()\n",
    "predicted"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型的保存与读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model.pkl'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 GPU 进行训练\n",
    "  - 只需要将数据和模型传到 cuda 里面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50, loss 1.5593505653388462e-11\n",
      "epoch 100, loss 1.5593505653388462e-11\n",
      "epoch 150, loss 1.5593505653388462e-11\n",
      "epoch 200, loss 1.5593505653388462e-11\n",
      "epoch 250, loss 1.5593505653388462e-11\n",
      "epoch 300, loss 1.5593505653388462e-11\n",
      "epoch 350, loss 1.5593505653388462e-11\n",
      "epoch 400, loss 1.5593505653388462e-11\n",
      "epoch 450, loss 1.5593505653388462e-11\n",
      "epoch 500, loss 1.5593505653388462e-11\n",
      "epoch 550, loss 1.5593505653388462e-11\n",
      "epoch 600, loss 1.5593505653388462e-11\n",
      "epoch 650, loss 1.5593505653388462e-11\n",
      "epoch 700, loss 1.5593505653388462e-11\n",
      "epoch 750, loss 1.5593505653388462e-11\n",
      "epoch 800, loss 1.5593505653388462e-11\n",
      "epoch 850, loss 1.5593505653388462e-11\n",
      "epoch 900, loss 1.5593505653388462e-11\n",
      "epoch 950, loss 1.5593505653388462e-11\n",
      "epoch 1000, loss 1.5593505653388462e-11\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device) # diff\n",
    "\n",
    "epochs = 1000\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss() # Mean Square Error\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch += 1\n",
    "\n",
    "    inputs = torch.from_numpy(x_train).to(device) # diff\n",
    "    labels = torch.from_numpy(y_train).to(device) # diff\n",
    "    \n",
    "    # 每一次迭代 梯度清零\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 前向传播\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # 计算损失\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # 反向传播\n",
    "    loss.backward()\n",
    "\n",
    "    # 更新权重参数\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
